{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42a8a2d3",
   "metadata": {},
   "source": [
    "# TP Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f6d58",
   "metadata": {},
   "source": [
    "Ce notebook est basé sur le numerical tour de *Gabriel Peyré* qui introduit les notions essentielles à la regression linéaire et logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c8eeb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec2e7a",
   "metadata": {},
   "source": [
    "Fonctions utiles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d8a2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  convert to a column vector\n",
    "def MakeCol(y): return y.reshape(-1,1)\n",
    "#  convert to a row vector\n",
    "def MakeRow(y): return y.reshape(1,-1)\n",
    "# find non zero/true elements\n",
    "def find(x): return np.nonzero(x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3e45d",
   "metadata": {},
   "source": [
    "## Exercice 1 : Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa789cd",
   "metadata": {},
   "source": [
    "### Data Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a95c2",
   "metadata": {},
   "source": [
    "Tout d'abord on simule un problème de régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28c8f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y, coef = datasets.make_regression(n_samples = 1000, n_features = 100,\n",
    "                                n_informative = 4, n_targets = 1,\n",
    "                                noise = 10.0, coef = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26f728",
   "metadata": {},
   "source": [
    "**Q: Que fait le code ci-dessus, que font les paramètres ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346e9038",
   "metadata": {},
   "source": [
    " Ce code génère un ensemble de données synthétiques pour une tâche de régression avec 100 échantillons, 10 caractéristiques dont 4 sont informatives, une seule cible à prédire, et ajoute du bruit gaussien. Les **données d'entrée**, les **valeurs cibles** et les **coefficients** utilisés pour générer les données sont stockés dans les variables **X**, **y** et **coef**, respectivement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f664f",
   "metadata": {},
   "source": [
    "**Q : Séparer le dataset en un ensemble d'apprentissage et de test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed4d6eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb2c16f",
   "metadata": {},
   "source": [
    "**Q : Pourquoi n'utilise-t-on pas d'ensemble de validation ici ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b328a592",
   "metadata": {},
   "source": [
    "Il n'y a pas d'hyperparamètre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899c15e",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Least square solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a723dd",
   "metadata": {},
   "source": [
    "On rappelle que l'estimateur des moindres carrés est donné par : $\\hat{\\beta} = (X^T X)^{-1} X^Ty $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf80ce90",
   "metadata": {},
   "source": [
    "**Q: Coder une fonction qui permet de calculer une estimation de celui-ci à partir des données.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2668ab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.33569890e-02 -2.52981441e-01  4.43709718e-01  3.86399348e-02\n",
      " -3.65428815e-02  2.46297038e-01  1.39226710e-01  5.66586987e+01\n",
      "  3.11710899e-01  2.32585207e-01  3.73198226e-01  1.75951930e-03\n",
      " -2.31949485e-01 -3.40718915e-01 -1.17619774e-02 -5.97715151e-01\n",
      "  2.22224850e-01 -3.78328271e-01  5.51583625e-02 -2.34301198e-01\n",
      " -2.28757937e-01 -3.01840389e-01  4.47393724e-02  3.34591494e+01\n",
      " -4.10297981e-01 -6.82122944e-01 -5.52180889e-02 -8.89267777e-01\n",
      " -1.80490197e-01 -1.96511276e-01  2.41780684e-02  6.16258269e-02\n",
      "  4.75574822e-01 -3.43298179e-01 -5.08133178e-01  4.30182767e-01\n",
      " -5.36012709e-02  5.00088111e-02 -2.14757185e-02 -1.73795894e-01\n",
      "  9.32696484e-02 -1.04044876e-02  1.13615189e-01 -2.99454066e-01\n",
      "  3.79115833e-01  2.24143107e-01 -1.95487694e-01 -6.16605551e-02\n",
      " -1.50225533e-01  1.52380280e-01 -8.44406130e-02 -7.76860634e-02\n",
      " -4.65765799e-01 -4.52521221e-01  3.50078229e-01 -2.56971137e-01\n",
      "  2.76203310e-01 -5.91441735e-01 -2.53723090e-01 -2.14779898e-01\n",
      " -2.35780794e-01 -4.87354501e-01  1.62063011e-01 -6.55344334e-01\n",
      "  2.71726027e-01  8.38084045e-02  6.18724799e-02 -2.78171932e-01\n",
      "  4.48485955e-02  1.21548273e-01 -3.47114594e-01 -1.87120447e-02\n",
      " -1.12760492e-01 -4.02318876e-01 -1.96801841e-01 -1.05859715e-01\n",
      "  2.58736691e-01 -2.75383756e-01 -6.11418977e-01  3.98095412e-01\n",
      "  1.35186624e-01 -4.00437972e-01  1.48451913e+01 -4.86792364e-01\n",
      "  2.77704740e-01 -2.52612948e-01  1.68608131e-02 -1.78908584e-01\n",
      " -4.36023465e-01  6.43840586e-02 -1.35822502e-02 -5.20984756e-01\n",
      "  6.54369776e-02 -4.53118927e-01  1.90694551e-01  9.69646167e+01\n",
      " -1.53559995e-01  4.62031178e-01  5.89004758e-01  1.14333914e-01]\n"
     ]
    }
   ],
   "source": [
    "def test(X,y) :\n",
    "    B = np.linalg.inv(np.dot(np.transpose(X),X))\n",
    "    B = np.dot(B,np.transpose(X))\n",
    "    return np.dot(B,y)\n",
    "\n",
    "def reg_OLS(X,y):\n",
    "    return np.linalg.inv(np.transpose(X)@X)@np.transpose(X)@y\n",
    "\n",
    "assert(test(X,y).all() == reg_OLS(X,y).all())\n",
    "print(reg_OLS(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75775ab8",
   "metadata": {},
   "source": [
    "**Q: Donner un avis sur les valeurs des paramètres. Que constate-t-on et pourquoi ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b2d9c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8846fa4b",
   "metadata": {},
   "source": [
    "**Q: Créer une fonction `reg_lin` qui permet de prédire les labels `y` pour de nouvelles données `X`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8711f795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.75474516e+02 -5.59104303e+01 -7.05235255e+01 -7.69947423e+01\n",
      " -3.95933020e+01  4.51945766e+01 -1.15105726e+02 -5.17670361e+01\n",
      "  6.99269511e+01 -3.43313313e+02  1.11750791e+02 -1.68198317e+02\n",
      " -1.10046444e+02 -5.87476683e+01 -1.23156371e+02  7.39474603e+01\n",
      "  2.98367182e+01  2.29635357e+02 -5.42509966e+01  1.10865890e+02\n",
      "  3.53414835e+01  7.03760715e+01 -2.16928485e+01  1.54832791e+02\n",
      " -1.47367070e+02 -1.11604030e+01  9.83694631e+01 -8.17780096e+01\n",
      " -1.65774677e+02  1.62410840e+02  6.21532528e+01  2.48592422e+02\n",
      " -1.35976652e+02  4.18065298e+01 -2.28902638e+02  4.09658978e+01\n",
      " -5.21562959e+01  1.75270438e+02 -1.07347814e+02 -1.92317759e+00\n",
      " -1.53842466e+02 -1.71741219e+02  3.05620659e+02 -9.88566655e+01\n",
      "  5.15050544e+01 -4.49573307e+01  1.21117438e+02 -7.04788153e+01\n",
      "  4.25337474e+01  2.79954370e+01 -1.11939110e+02  1.14039243e+02\n",
      " -8.13948884e+01 -7.05557286e+01  4.21520345e+01  1.88381255e+01\n",
      "  1.88895560e+02 -1.74427974e+01 -1.97940183e+01  5.50100120e+01\n",
      " -9.88563176e+01  1.17530033e+01  8.92311048e+01  2.68982404e+01\n",
      " -2.44123479e+02 -1.79429013e+02  4.58845366e+01 -1.19797427e+02\n",
      " -9.14589816e+01 -4.04217133e+01 -1.13277096e+02  8.28248368e+00\n",
      "  1.23206869e+02 -1.82713454e+02 -3.95776725e+01  4.40994425e+01\n",
      "  3.17932054e+01  3.65020709e+01  1.76900942e+02  3.94896990e+01\n",
      " -4.36424858e+02 -1.64378859e+02  6.39970822e+01  1.07438119e+02\n",
      "  1.36015219e+02 -7.33075938e+01 -9.24111739e+00  1.63762976e+01\n",
      "  5.52954952e+01  3.08071458e+01 -1.09263985e+02  3.33048124e+00\n",
      "  8.86661268e+01  3.01395927e+01  1.23307785e+02 -1.34723404e+02\n",
      "  1.38581700e+02  7.14139231e+01 -2.26673605e+02  7.95074745e+01\n",
      "  1.56675543e+02 -7.68142886e+01 -1.70703767e+02 -4.11933935e+01\n",
      " -1.19624456e+01 -1.20218241e+02 -1.74400417e+02 -1.45689861e+02\n",
      "  1.32403335e+02 -2.12340354e+02  8.57013852e+01 -6.32789051e+01\n",
      "  1.34067367e+02 -7.41434391e+01 -1.38912822e+02  2.45544063e+02\n",
      " -4.90874061e+01 -2.81423233e+01 -2.54960489e+01 -1.36355412e+02\n",
      " -1.19683811e+02  1.61000324e+01 -8.10352106e+01 -2.11999333e+02\n",
      "  7.84644962e+00  3.18155600e+01  5.80899548e+01  1.89629082e+02\n",
      " -5.27777852e+00  7.52976478e+00 -2.18725611e+01 -1.59305512e+02\n",
      " -3.62157523e+01  1.06106965e+02  1.91683519e+02  2.83285244e+01\n",
      "  5.43553546e+01  7.06447340e+01 -2.27564291e+02  8.79640730e+01\n",
      " -3.87800188e+00 -2.81801171e+01  1.26720401e+02 -1.44585837e+01\n",
      " -1.39349729e+02  6.74092902e+01 -7.30413893e+01  2.17900952e+02\n",
      " -7.50864118e+01  1.85753798e+01  2.37534970e+02 -1.82356059e+02\n",
      " -2.69090468e+01 -1.34316093e+02  1.49632842e+02 -1.06865233e+02\n",
      " -7.98861169e+01  2.62923978e+01 -3.45379417e+01  1.65092884e+02\n",
      " -1.20194590e+02 -1.23793200e+01  2.29220822e+02  3.57410848e+00\n",
      " -2.21514328e+02 -1.06991632e+02 -2.75526918e+01 -1.48204352e+02\n",
      " -3.05375485e+01 -1.16564314e+02 -3.49598866e+01 -1.09421881e+02\n",
      "  1.16473279e+02 -1.08179735e+02 -1.02134559e+02  1.56227436e+02\n",
      "  5.82005111e+01  2.45280622e+02  1.29562931e+02 -2.85977508e+01\n",
      "  6.51824056e+01  5.33418524e+01 -1.33780179e+02 -1.97609972e+02\n",
      "  9.68783983e+01  3.56167523e+01 -4.45876190e+01  9.03666406e+01\n",
      "  5.93731469e+01  1.21731410e+02  4.62792027e+01 -1.60662714e+02\n",
      "  5.68664802e+00  1.30079533e+02 -8.88156071e+01  1.70904857e+02\n",
      " -6.05202771e+01  4.42391240e+01 -2.11201543e+01  4.30053706e-01\n",
      " -5.06979715e+01  7.62901925e+01  1.65985683e+02 -4.06160583e+02\n",
      "  5.71310725e+00 -1.42019539e+01  6.50486386e+01  1.79092470e+02\n",
      "  2.63565555e+01  1.43425986e+02 -3.99304324e+01  1.39597586e+02\n",
      " -4.48248996e+01 -7.64978165e+01  1.25086839e+02  1.82314975e+01\n",
      " -6.00737745e+01 -2.11752202e+02 -2.01077515e+02  7.81370044e+01\n",
      " -9.46553701e+01 -6.53221798e+01  5.27522171e+01 -1.90587230e+01\n",
      "  1.93083069e+02 -4.41160732e+01  9.64551162e+01  9.07190975e+01\n",
      "  2.84806311e+01 -1.86539495e+02  7.31542917e+00 -6.02549864e+00\n",
      "  4.12639321e+01  1.73847677e+02 -1.36444987e+02 -5.31007468e+00\n",
      " -9.02803100e+01  1.87063020e+02  1.09928942e+02 -2.91790574e+01\n",
      "  3.64038937e+01  9.80659683e+01 -1.66691596e+02  9.00685795e+01\n",
      " -1.69025245e+02 -5.14563422e+01 -1.05117004e+02 -1.84991108e+02\n",
      "  7.62183141e+01  6.15085241e+01 -2.23012355e+01  1.27571801e+02\n",
      " -6.82846542e+01 -8.67209035e+01 -1.15244960e+01  8.86571949e+01\n",
      "  5.29781351e+01  2.31206933e+02 -1.56892575e+02 -1.28365448e+02\n",
      " -1.40471775e+02 -2.05370904e+01 -2.31726065e+02  8.12313519e+01\n",
      "  1.20946754e+02 -7.57224659e+01  7.36976419e+01 -8.96694460e+01\n",
      "  4.84566681e+01  1.37859897e+02 -8.95253298e+01 -1.00696288e+02\n",
      " -9.27550370e-01  5.75038685e+01 -7.19415245e+01 -6.22082394e+01\n",
      " -2.62356472e+02  1.22304678e+02  6.83453263e+01  4.68896839e+00\n",
      "  6.67185935e+01  3.62603270e+01 -1.18614781e+01  1.74448290e+02\n",
      " -2.82530235e+01  1.57225892e+01 -1.78917641e+01  3.85343186e+01\n",
      " -1.11406563e+02  7.36701830e+01  7.08468640e+01 -1.21350475e+02\n",
      "  8.18626535e+01  1.17922050e+02 -1.96752348e+02 -1.63551574e+02\n",
      "  1.11791702e+02 -1.70754128e+02 -1.12185454e+02 -3.31150364e+01\n",
      "  7.90355624e+01 -5.83543295e+01  2.42200248e+02 -1.71553039e+02\n",
      "  2.65211601e+02 -1.92811698e+01  3.44543262e+01 -7.80226590e+00\n",
      "  6.99215470e+00  3.91869743e+01  8.94989154e+01  8.50276912e+01\n",
      "  2.59005930e+01 -7.95139410e+01 -1.89675324e+01  3.41814436e+01\n",
      "  3.66579271e+01 -2.90328431e+01 -7.86558062e+01 -1.28104799e+02\n",
      " -7.55105593e+01  1.64409258e+02 -1.69759359e+01  6.10813196e+00\n",
      " -1.06658090e+02 -1.82117975e+02 -3.53192293e+01  5.91162216e+01\n",
      "  3.12117081e+01 -1.55262923e+01 -9.50405201e+01  1.76414004e+02\n",
      " -6.51223461e+01 -9.79327189e+01  3.60886827e+01 -1.02769564e+02\n",
      " -2.75358024e+01 -1.31566236e+02 -8.13265767e+01  2.02891727e+02\n",
      "  3.40029936e+01  1.72116165e+02  7.19696446e+01 -1.97934090e+02\n",
      " -1.16457194e+01 -1.47252206e+02 -9.46742577e+01 -4.61061211e+01\n",
      " -2.20781076e+02 -1.37701634e+02  8.21701529e+01  2.57501794e+01\n",
      "  1.77908632e+02  7.12581941e+01  3.90212788e+01  9.99142594e+01\n",
      "  1.42695964e+01  1.07012825e+02 -1.73176114e+02 -5.49833927e+01\n",
      "  1.84577664e+02 -5.41669111e+01 -1.66215292e+02  2.55413176e+01\n",
      " -4.24644360e+00 -2.66894151e+01  3.59580268e+01 -6.12318751e+01\n",
      " -1.62325158e+02 -9.20155975e+01 -2.15576556e+02  8.73894131e+00\n",
      "  5.23694905e+01 -2.14134875e+02  2.05931091e+02 -6.60084353e+01\n",
      " -1.34145071e+02 -1.25852211e+02  1.12276329e+02  5.71956221e+01\n",
      " -3.35701147e+01 -6.05241992e+01 -2.40669398e+01 -1.87759770e+02\n",
      "  9.57413411e+01  4.31776339e+01 -1.65623042e+02 -1.03081811e+02\n",
      " -1.20808223e+02 -8.48921634e+01  5.54289846e+01  1.80572551e+02\n",
      " -7.95384767e+01  1.64902388e+02  6.92346673e+01 -1.17818743e+00\n",
      " -6.78269128e+01  7.28624792e+01  1.47294319e+02  3.68355107e+00\n",
      " -4.60600524e+01  1.70767794e+02 -1.65630360e+02  6.86490730e+01\n",
      "  1.70977163e+02 -1.81298701e+02 -1.36893725e+02  1.60947075e+02\n",
      "  4.91968005e+01 -6.04027110e+01 -6.17664567e+01 -1.26649872e+02\n",
      " -9.58037778e-01  2.03008355e+02  5.15869832e+01  2.04388423e+02\n",
      "  2.08292154e+02  8.89169262e+01  4.51526204e+01 -2.62541538e+01\n",
      " -1.25048078e+02  6.16674684e+01 -1.73491125e+01 -9.01214275e+01\n",
      "  1.17741099e+02  1.51143504e+02  1.35659736e+02 -3.14459366e+01\n",
      "  2.80993415e+01  1.45993449e+02  1.59211745e+02 -9.21038637e+01\n",
      "  1.65111311e+02  4.33890141e+01 -1.62073515e+02 -4.60364373e+01\n",
      "  4.98414946e+01  5.96218331e+01 -2.16704766e+02 -2.26182534e+01\n",
      " -9.26202548e+01  1.97446764e+01  6.68472882e+00  5.54679095e+00\n",
      "  5.82826627e+01  1.60997218e+02 -2.21822725e+02 -1.56682168e+02\n",
      " -2.18762778e+02 -2.18021805e+01 -6.38835192e+00  1.08625396e+01\n",
      " -4.81958900e+01 -1.88513466e+02  3.42039155e+01  1.19550360e+02\n",
      " -1.23396179e+02 -2.23481886e+02 -6.26383191e+01  3.01103597e+01\n",
      "  5.02088181e+01 -1.04306275e+02 -1.97803790e+02 -1.59262808e+00\n",
      "  9.50834440e+00 -2.62976353e+01  6.88239966e+01 -8.04555805e+01\n",
      "  1.67582513e+02  5.32762169e+00  2.95366335e+01 -6.40252764e+01\n",
      "  1.94977183e+01  4.08812903e+01  3.90197925e+01 -2.80966892e+01\n",
      " -5.41196493e+01  3.64922479e+01  1.64928407e+02 -2.51284953e+01\n",
      "  1.69352860e+02 -4.64515474e+01  8.04241697e+00 -1.46761409e+02\n",
      " -1.55749437e+02  2.93700130e+02  9.87833282e+00 -1.48434389e+02\n",
      "  1.38160667e+02  1.06698260e+02 -9.02914514e+01  8.24408798e+01\n",
      "  2.27329263e+02  1.13719506e+02 -1.31886613e+02 -2.72059725e+01\n",
      " -6.51284927e+01  5.04633371e+01 -2.36026188e+02  3.08404486e+01]\n"
     ]
    }
   ],
   "source": [
    "def reg_lin(X_train,X_test,y):\n",
    "    coeff = reg_OLS(X_train,y)\n",
    "    y_pred = X_test @ coeff\n",
    "    return y_pred\n",
    "\n",
    "Y_pred = reg_lin(X_train,X_test,Y_train)\n",
    "print(Y_pred)\n",
    "#données proche de 0 si on augmente n_samples (=100), n_features (=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476d2a02",
   "metadata": {},
   "source": [
    "**Q : Tester sur l'ensemble de test. Quel taux d'erreur avez-vous ? Que pouvez-vous dire ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1faea49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13694.754803677026\n",
      "166.77374646487652\n"
     ]
    }
   ],
   "source": [
    "def root_mean_squared_error(y_true,y_pred):\n",
    "    return math.sqrt(((y_true-y_pred)**2).mean())\n",
    "\n",
    "print(np.var(Y_pred))\n",
    "print(root_mean_squared_error(Y_train,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed6e52",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Descente de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483827ef",
   "metadata": {},
   "source": [
    "On rappelle que l'objectif est de minimiser $f(\\beta) = \\frac{1}{2} \\| X\\beta - y \\|^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f42e80",
   "metadata": {},
   "source": [
    "**Q: Coder la fonction de perte (loss) `f` qui prend en paramètres la matrice X, y et $\\beta$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cb936fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X,y,B):\n",
    "    return 0.5*np.linalg.norm(X@B-y)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ffaf94",
   "metadata": {},
   "source": [
    "On rappelle aussi que le gradient de $f$ est : $\\nabla f(\\beta) = X^T(X\\beta - y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13a8d6",
   "metadata": {},
   "source": [
    "**Q: Coder la fonction  `grad_f` qui prend en paramètre la matrice X, y et $\\beta$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0629197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_f(X,y,B):\n",
    "    return np.transpose(X)@(X@B-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f665782",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "Maintenant, codons la descente de gradient, on rappelle que le passage de l'algorithme de l'étape $m$ à $m+1$ est donné par :\n",
    "$$\n",
    "\\beta^{(m+1)} = \\beta^{(m)} - \\tau \\nabla f(\\beta^{(m)}),\n",
    "$$\n",
    "où $\\tau$ est le pas de la descente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad2c27",
   "metadata": {},
   "source": [
    "**Q : Coder la fonction `Reg_lin_desc_grad` qui prend en entrée :`X`,`y`, `w` (initialisation de beta), `tau`, `n_iter` (le nombre d'itérations maximum), `tol` (la tolérance de la convergence).**\n",
    "\n",
    "Dans un second temps, cette fonction doit aussi afficher l'evolution de l'erreur d'entraînement comme une fonction du nombre d'itération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d58f4a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m B[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m B[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mReg_lin_desc_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[41], line 4\u001b[0m, in \u001b[0;36mReg_lin_desc_grad\u001b[0;34m(X, y, w, tau, n_iter, tol, plot)\u001b[0m\n\u001b[1;32m      2\u001b[0m B \u001b[38;5;241m=\u001b[39m [w]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,n_iter\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     B\u001b[38;5;241m.\u001b[39mappend(\u001b[43mB\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m tau\u001b[38;5;241m*\u001b[39mgrad_f(X,y,B[i]))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mabs\u001b[39m(B[i]\u001b[38;5;241m-\u001b[39mB[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m<\u001b[39m tol):\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m B[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def Reg_lin_desc_grad(X,y,w,tau = 1/np.linalg.norm(X,2)**2 ,n_iter=50,tol = 1e3,plot=True):\n",
    "    B = [w]\n",
    "    for i in range(1,n_iter+1):\n",
    "        B.append(B[i] - tau*grad_f(X,y,B[i]))\n",
    "        if (abs(B[i]-B[i-1]) < tol):\n",
    "            return B[-1]\n",
    "    return B[-1]\n",
    "\n",
    "print(Reg_lin_desc_grad(X,y,np.ones(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232270d0",
   "metadata": {},
   "source": [
    "La variable `tau` définie en amont est donnée par un critère du controle de norme, il ne faut pas que le pas de l'algorithme dépasse  :\n",
    "$$\n",
    "\\tau_{max} = \\dfrac{2}{\\| X X^T\\|_{op}},\n",
    "$$\n",
    "avec $\\| .\\|_{op}$ est la valeur propre maximal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3da956",
   "metadata": {},
   "source": [
    "**Q : Tester pour différentes valeurs de $\\tau$, que constatez-vous ?** (Convergence, estimation, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88afba16-6b36-4c5b-918b-bd38ac14d251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5d895c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c9260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "Model_LinearReg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff15ca3",
   "metadata": {},
   "source": [
    "**Q: Que contient cet objet ? Comment mettre à jour ses poids ? Que dire des paramètres ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e6a03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e85b73a",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  OLS / Gradient descent / Scikit-learn (learning time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b07850",
   "metadata": {},
   "source": [
    "Cette partie dépendra grandement de votre machine et de votre implémentation, toutefois elle permettra de vous faire une idée quant au choix de la méthode à privilégier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time \n",
    "t1 = time() \n",
    "#Quelque chose\n",
    "t2 = time()\n",
    "elapsed = t2 - t1 \n",
    "print('Elapsed time is %f seconds.' % elapsed) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce75632",
   "metadata": {},
   "source": [
    "**Q : Que fait le code ci-dessus ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac8e22",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0904d05",
   "metadata": {},
   "source": [
    "**Q: Afficher l'évolution du temps de calcul en faisant varier le nombre d'individus dans le dataset  N = 100 : 100000 (pas logartihmique) et en laissant fixé p = 40.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599d486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42997943",
   "metadata": {},
   "source": [
    "**Q: Afficher l'évolution du temps de calcul en faisant varier le nombre de variables dans le dataset p = 40:5000 (pas logarithmique) et en laissant le nombre d'individus fixé N = 10000.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa46ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcd8359c",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Gradient descent / Scikit-learn (performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd72b3",
   "metadata": {},
   "source": [
    "**Q: Comparer les performances de prédiction sur l'ensemble de test. Y a-t-il des différences ? Si oui, pourquoi ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1f13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99fcde26",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercice 2 : Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74cb0e9",
   "metadata": {},
   "source": [
    "### Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000 # number of sample\n",
    "p = 2 # dimensionality\n",
    "omega = np.array([1,.5])*2.5 # offset \n",
    "n1 = int(n/2)\n",
    "X = np.vstack(( np.random.randn(n1,2), np.random.randn(n1,2)+np.ones([n1,1])*omega ))\n",
    "y = np.vstack(( np.ones([n1,1]), -np.ones([n1,1]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf63426",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = find(y==-1)\n",
    "J = find(y==1)\n",
    "plt.clf\n",
    "plt.plot(X[I,0], X[I,1], '.')\n",
    "plt.plot(X[J,0], X[J,1], '.')\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9d4ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Descente de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28cff97",
   "metadata": {},
   "source": [
    "On rappelle que l'objectif de minimiser $g(\\beta) = \\dfrac{1}{n} \\sum_{i=1:n}  \\log(1 + e^{-yi \\langle X_i , \\beta \\rangle})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19875cb",
   "metadata": {},
   "source": [
    "**Q: Coder la fonction de loss `g` qui prend en paramètre la matrice X, y et $\\beta$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131ace5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc38a6f2",
   "metadata": {},
   "source": [
    "On rappelle aussi que le gradient de $g$ est : $$\\nabla g(\\beta) = \\dfrac{1}{n} X^T y \\odot \\sigma(- y \\ \\odot <X,\\beta>),$$\n",
    "où $\\odot$ est le produit élément par élément (* en python) et $\\sigma$ est la fonction sigmoide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fef39",
   "metadata": {},
   "source": [
    "**Q: Coder la fonction  `grad_g` qui prend en paramètre la matrice X, y et $\\beta$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600676db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_g():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b9cdd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "Maintenant, codons la descente de gradient. On rappelle que le passage de l'algorithme de l'étape $m$ à $m+1$ est donné par :\n",
    "$$\n",
    "\\beta^{(m+1)} = \\beta^{(m)} - \\tau \\nabla g(\\beta^{(m)}),\n",
    "$$\n",
    "où $\\tau$ est le pas de la descente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f364b",
   "metadata": {},
   "source": [
    "**Q : Coder la fonction `Reg_log_desc_grad` qui prend en entrée :`X`,`y`, `w` (initialisation de beta), `tau`, `n_iter` (le nombre d'itérations maximum), `tol` (la tolérence de la convergence).**\n",
    "\n",
    "Dans un second temps, cette fonction doit aussi afficher l'évolution de l'erreur d'entraînement comme une fonction du nombre d'itération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reg_log_desc_grad(X,y,w,tau = 1/np.linalg.norm(X,2)**2 ,n_iter=50,tol = 1e3,plot=True):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab7e2a",
   "metadata": {},
   "source": [
    "La variable `tau` définie en amont est donnée par un critère du contrôle de la norme, il ne faut pas que le pas de l'algorithme dépasse  :\n",
    "$\n",
    "\\tau_{max} = \\dfrac{2}{ 1/4\\| X \\|_{op}^2},\n",
    "$\n",
    "avec $\\| .\\|_{op}$ est la valeur propre maximale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdafa9f",
   "metadata": {},
   "source": [
    "**Q : Tester différentes valeurs de $\\tau$, que constatez-vous ?** (Convergence, estimation, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ac9dc-f8cc-4232-8223-5490e30afda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c4c4171",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca7aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Model_LogReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc8c620",
   "metadata": {},
   "source": [
    "**Q: Que contient cet objet ? Comment mettre à jour ses poids ? Que dire des paramètres ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39629f73",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79b0b39b",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Gradient descent / Scikit-learn (learning time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ea0f10",
   "metadata": {},
   "source": [
    "Cette partie dépendra grandement de votre machine et de votre implémentation, toutefois elle permettra d'avoir des idées de quand utiliser un algorithme plutôt que l'autre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd98302-3ab5-40bd-aa05-7fe3a7812d07",
   "metadata": {},
   "source": [
    "On pose $\\beta^\\star_j = (-1)^{j-1} \\exp(-(j-1)/10)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a10a58-7da2-45a6-9389-fe586789cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 40\n",
    "n_samples = 2000\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "idx = np.arange(n_features)\n",
    "params = (-1) ** idx  * np.exp(-idx / 10.)\n",
    "params[20:] = 0.\n",
    "plt.stem(params)\n",
    "plt.title(\"Parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24301b7-4520-49e4-b6c3-480c060fc260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "def sigmoid(a):\n",
    "    x = copy.deepcopy(a)\n",
    "    if(x.size ==1) :\n",
    "        if x >= 0:\n",
    "            return 1.0 / (1.0 + np.exp(-x))\n",
    "        else : \n",
    "            # Utilisez la formule sigmoid(x) = 1 - sigmoid(-x) pour x < 0\n",
    "            return np.exp(x) / (1.0 + np.exp(x))\n",
    "        \n",
    "        \n",
    "    neg_part = find(x<=0)\n",
    "    pos_part = find(x>0)\n",
    "    if pos_part.size >= 0:\n",
    "        x[pos_part] = 1.0 / (1.0 + np.exp(-x[pos_part]))\n",
    "        \n",
    "    if neg_part.size >= 0: \n",
    "        x[neg_part] = np.exp(x[neg_part]) / (1.0 + np.exp(x[neg_part]))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7b936-80e4-4a90-9c2c-6388fb186b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import multivariate_normal\n",
    "from scipy.linalg.special_matrices import toeplitz\n",
    "from numpy.random import binomial\n",
    "def simu_logreg(n_samples,params=params,rho=0.1):\n",
    "    \"\"\" simulation in a logistic regression model \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coefs : `numpy.array`, shape=(n_features,)\n",
    "        Coefficients of the model\n",
    "    n_samples : `int`, \n",
    "        Number of samples to simulate\n",
    "    rho : `float`, default=0.1\n",
    "        Correlation of the features\n",
    "    Returns\n",
    "    -------\n",
    "    X : `numpy.ndarray`, shape=(n_samples, n_features)\n",
    "    Simulated features matrix. It samples of a centered Gaussian\n",
    "    vector with covariance given by the Toeplitz matrix\n",
    "    y : `numpy.array`, shape=(n_samples,)\n",
    "                 Simulated labels\n",
    "    \"\"\"\n",
    "    n_features = params.size\n",
    "    \n",
    "    cov = toeplitz(rho ** np.arange(0, n_features))\n",
    "    \n",
    "    features = multivariate_normal(np.zeros(n_features), cov, size=n_samples)\n",
    "    \n",
    "    pis = sigmoid(features.dot(params))\n",
    "    \n",
    "    labels = 2 * ( binomial(1,pis, n_samples) - 1)\n",
    "    \n",
    "    return((features,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd9e275-5c88-4b1d-a76f-c53f8309d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_perfs,y_perfs = simu_logreg(2000,params,rho = 0.1)\n",
    "print(y_perfs.shape)\n",
    "print(X_perfs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237198c1-50f3-472a-84ea-8c2998cb882d",
   "metadata": {},
   "source": [
    "**Q: Que fait le code ci-dessus ? Détailler.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c6d65-b4d2-444e-878e-e0261da1ebf1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1637ed9d-a2a9-4421-9474-80977049fb52",
   "metadata": {},
   "source": [
    "**Q: Afficher l'évolution du temps de calcul en fonction du nombre d'individus dans le dataset  N = 100 : 100000 et p = 40** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a29c2d-f14b-495e-9069-1e90f4538310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e4bdd52-3cb6-4cde-b29b-93d17906c088",
   "metadata": {},
   "source": [
    "**Q: Afficher l'évolution du temps de calcul en fonction de variables dans le dataset  N = 10000 et p = 40:5000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9739e-7d8d-42d1-a537-ea91e4601690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0c7fe4b",
   "metadata": {},
   "source": [
    "**Q: Afficher l'évolution du temps de calcul en faisant varier le nombre d'individus dans le dataset  N = 100 : 100000 (pas logartihmique) et en laissant fixé p = 40.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7316c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b7e55d",
   "metadata": {},
   "source": [
    "**Q: Afficher l'évolution du temps de calcul en faisant varier le nombre de variables dans le dataset p = 40:5000 (pas logarithmique) et en laissant le nombre d'individus fixé N = 10000.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96bd175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cbd66e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Gradient descent / Scikit-learn (performances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1348ff26",
   "metadata": {},
   "source": [
    "**Q: Comparer les performances de prédiction sur l'ensemble de test. Y a-t-il des différences ? Si oui, pourquoi ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03973b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89b4d188",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Frontières de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c9575",
   "metadata": {},
   "source": [
    "En utilisant les fonctions de régression logistique (au choix : celle que vous avez implémentée ou celle de scikit-learn) on va maintenant tracer les frontières de décisions de notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07c883",
   "metadata": {},
   "source": [
    "On génère une grille de points en 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 201\n",
    "tx = np.linspace( X[:,0].min(), X[:,0].max(),num=q) \n",
    "ty = np.linspace( X[:,1].min(), X[:,1].max(),num=q) \n",
    "[B,A] = np.meshgrid( ty,tx )\n",
    "G = np.vstack([A.flatten(), B.flatten()]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddfd4ba",
   "metadata": {},
   "source": [
    "**Q: Calculer les probabilités de classe associées à chacun des vecteurs composant la grille.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fe857",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_pred = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_class1 = proba_pred[:,0].reshape(q,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec5c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf\n",
    "plt.imshow(proba_class1.transpose(), origin=\"lower\",  extent=[tx.min(),tx.max(),ty.min(),ty.max()])\n",
    "plt.axis('equal')\n",
    "plt.plot(X[I,0], X[I,1], '.')\n",
    "plt.plot(X[J,0], X[J,1], '.')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0667d0b1",
   "metadata": {},
   "source": [
    "## Exercice 3 : Penalized Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ae158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(LogisticRegression)\n",
    "help(LinearRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced8fe4",
   "metadata": {},
   "source": [
    "**Q: Dans l'aide, quel est l'argument qui permet de gérer la pénalité utilisée ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d46e5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78314b8e",
   "metadata": {},
   "source": [
    "**Q: [Regression] Comparer les différentes pénalisations en termes de performances sur l'ensemble d'apprentissage et de test ainsi que sur l'estimation des coefficients. Commenter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65045793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a908218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df73e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496c8022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c4ee6b7",
   "metadata": {},
   "source": [
    "**Q: [Classification] Comparer les différentes pénalisations en termes de performances sur l'ensemble d'apprentissage et de test ainsi que sur l'estimation des coefficients. Commenter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d93fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8e916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df085d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf131f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "725521b4",
   "metadata": {},
   "source": [
    "**Q: Créer une procédure d'optimisation des hyper-paramètres.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e45ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e78d4dca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercice 4 : Decision Tree and random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bfa76e",
   "metadata": {},
   "source": [
    "### Arbre de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072d70a",
   "metadata": {},
   "source": [
    "The DecisionTreeClassifier() of the library ‘tree’ implements the decision tree for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948a008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c8647",
   "metadata": {},
   "source": [
    "**Q: Quels sont les hyper-paramètres d'un arbre de décision ? Quelless sont les valeurs par défaut de `DecisionTreeClassifier()`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0038e415",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cb2fc2c",
   "metadata": {},
   "source": [
    "**Q: Calculer la prédiction des classes associées à toutes les entrées de l'ensemble des données de la grille et visualiser les frontières de décision.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098872f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "r = export_text(treefit); # treefit -> Model\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9496b6",
   "metadata": {},
   "source": [
    "**Q: Que fait le code ci-dessus ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781a109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90e2a589",
   "metadata": {},
   "source": [
    "**Q: Créer une procédure d'optimisation des hyper-paramètres.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7cf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47cda2e3",
   "metadata": {},
   "source": [
    "### Forêts aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f036853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfbc00",
   "metadata": {},
   "source": [
    "**Q: Quels sont les hyper-paramètres d'un arbre de décision ? Quelles sont les valeurs par défaut de `DecisionTreeClassifier()`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6f7f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b459b600",
   "metadata": {},
   "source": [
    "**Q: Calculer la prédiction des classes associées à toutes les entrées de l'ensemble de données de la grille et visualiser les frontières de décision.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9d537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae8657a1",
   "metadata": {},
   "source": [
    "**Q: Créer une procédure d'optimisation des hyper-paramètres.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ebab23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bec28531",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercice 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fcc4e5",
   "metadata": {},
   "source": [
    "**Q: Appliquer tout ce que vous avez vu au cours de ce TP au dataset [Maternal Health Risk](https://archive.ics.uci.edu/dataset/863/maternal+health+risk).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e539a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4829371-a376-4e7d-95c2-b99e874c4a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
